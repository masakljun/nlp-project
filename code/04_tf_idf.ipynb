{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3c16ba0",
   "metadata": {},
   "source": [
    "# TF-IDF\n",
    "In this notebook we include the key word extraction that is in the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acting-chart",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import nltk\n",
    "import re\n",
    "import pandas as pd\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer \n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "thirty-switzerland",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\matij\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\matij\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "promotional-london",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fucks sake go away stupid anon — ^  https://t....</td>\n",
       "      <td>abusive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Damn dean just put Corbin to sleep. That Match...</td>\n",
       "      <td>abusive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@TheRealCamerota THAT BEER BUYING FREAKING IDI...</td>\n",
       "      <td>abusive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what idiot called them antacids and not afterb...</td>\n",
       "      <td>abusive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @gogglepossum: Don't you hate people that p...</td>\n",
       "      <td>abusive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    label\n",
       "0  fucks sake go away stupid anon — ^  https://t....  abusive\n",
       "1  Damn dean just put Corbin to sleep. That Match...  abusive\n",
       "2  @TheRealCamerota THAT BEER BUYING FREAKING IDI...  abusive\n",
       "3  what idiot called them antacids and not afterb...  abusive\n",
       "4  RT @gogglepossum: Don't you hate people that p...  abusive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"dataset/data.csv\", sep = \";\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9867aa38",
   "metadata": {},
   "source": [
    "## Select the label for key word extraction here!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "correct-advertising",
   "metadata": {},
   "source": [
    "#### Available labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "shared-archive",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abusive',\n",
       " 'benevolent',\n",
       " 'cyberbulling',\n",
       " 'hate',\n",
       " 'hateful',\n",
       " 'identity',\n",
       " 'insult',\n",
       " 'obscene',\n",
       " 'offensive',\n",
       " 'profane',\n",
       " 'racism',\n",
       " 'sexism',\n",
       " 'spam',\n",
       " 'threat',\n",
       " 'toxic'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(data[\"label\"].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3461bf",
   "metadata": {},
   "source": [
    "#### Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89d29579",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"racism\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "settled-mystery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148\n",
      "148\n"
     ]
    }
   ],
   "source": [
    "df = data[data[\"label\"] == label]\n",
    "\n",
    "labels = df[\"label\"].tolist()\n",
    "print(len(labels))\n",
    "\n",
    "texts = df[\"text\"].tolist()\n",
    "print(len(texts))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becoming-announcement",
   "metadata": {},
   "source": [
    "#### Preprocessing our tweets by removing retweet text RT, hyperlinks, hashtags, taggs @, new lines, and zero length tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "liable-outdoors",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(A, labels):\n",
    "    B = []\n",
    "    labels_new = []\n",
    "    for i in range(len(A)):\n",
    "\n",
    "        text = A[i]\n",
    "        # remove old style retweet text \"RT\"\n",
    "        text = re.sub(r'^RT[\\s]+', '', text)\n",
    "\n",
    "        # remove hyperlinks\n",
    "        text= re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text)\n",
    "\n",
    "        # remove hashtags\n",
    "        # only removing the hash # sign from the word\n",
    "        text = re.sub(r'#', '', text)\n",
    "\n",
    "        # remove tagging @\n",
    "        text = re.sub(r\"(?:\\@|https?\\://)\\S+\", \"\", text)\n",
    "\n",
    "        # remove new line \\n\n",
    "        text = re.sub(\"\\n\", \"\", text)\n",
    "\n",
    "        # remove zero length tweets\n",
    "        if(len(text) == 0 ):\n",
    "            continue\n",
    "\n",
    "        B.append(text)\n",
    "        labels_new.append(labels[i])\n",
    "    return B, labels_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "confused-lighter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts, labels = preprocess(texts, labels)\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "middle-beads",
   "metadata": {},
   "source": [
    "#### Merge lists into one large list of tweets. Filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "spatial-martin",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)\n",
    "\"\"\"\n",
    "def tokenize(text):\n",
    "    filtered_tokens = []\n",
    "    tweet_tokens = tokenizer.tokenize(text)\n",
    "\n",
    "    for token in tweet_tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    return filtered_tokens\n",
    "\n",
    "\"\"\"\n",
    "def tokenize_only(text):\n",
    "    # First tokenize by sentence, then by word to ensure that punctuation is caught as it's own token.\n",
    "    #tokens = [word.lower() for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    filtered_tokens = []\n",
    "    # Filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation).\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    return filtered_tokens\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "\n",
    "def tokenize_and_stem(text):\n",
    "    #tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    filtered_tokens = []\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "\n",
    "    #exclude stopwords from stemmed words\n",
    "    stems = [stemmer.stem(t) for t in filtered_tokens]\n",
    "    \n",
    "    return stems\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "appointed-shelter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['These girls are the equivalent of the irritating Asian girls a couple years ago. Well done, 7. MKR',\n",
       " \"Drasko they didn't cook half a bird you idiot mkr\",\n",
       " 'Hopefully someone cooks Drasko in the next ep of MKR',\n",
       " \"of course you were born in serbia...you're as fucked as A Serbian Film MKR\",\n",
       " 'So Drasko just said he was impressed the girls cooked half a chicken.. They cooked a whole one  MKR',\n",
       " '\"He can\\'t be a server at our restaurant, that beard makes him look like a terrorist.\" Everyone laughs. fuckthanksgiving',\n",
       " '   SANTA JUST *IS* WHITE',\n",
       " '  Why do people even talk about white privilege when the majority of food stamp recipients are white people!!',\n",
       " ' In his Ferguson testimony, Darren Wilson said he thought \"it looks like a demon\" before he shot Mike Brown. Ironic word…',\n",
       " ' I spent the morning at the Board of Elections getting maps/data to start registering every black person in Ferguson. ht…',\n",
       " ' Eric Holder from ferguson: \"I understand that mistrust. I am the Attorney General, but I am also a Black Man\" ',\n",
       " \" At least you're only a tiny bit racist RT  I'm not racist, but my dick is!\",\n",
       " ' GermanProfessor gives meaning to term FemiNazi.Doesn\\'t hire \"Indian Men\" bcz of \"Indias\\'s Rape Problem\"',\n",
       " 'cohen coon PowerPoint Slides - ',\n",
       " \"Repost totalblacktv1Don't ask me to think.......I just want to entertain! coon cooning… \",\n",
       " 'BlameOneNotAll is bad because I should be able to hate entire demographics of people for the bad things individuals do to me! racismyall',\n",
       " ' i seriously only see white.',\n",
       " ' dude we were the best team ever. We made shit happen! aggies Coon',\n",
       " 'Man wtf is this damn Coon ass nigga BillyBlanks doing on that damn commercial? ? CooneryAtItsFinest',\n",
       " \"Now streaming - World PvP, Ashran, killin' stuff\",\n",
       " \"  Not fascism, no no no. Just 'common sense nationalism'. What are you: some kind of leftard feminazi?!\",\n",
       " \"What if my skin is so white it glows, and I've got blue hair? ladylike \",\n",
       " \"   Would you prefer I say Massa. Oh I don't wana speak ill of my masse da white man. housenigga…\",\n",
       " \"  Why would anyone want to hire a rockstar anything? I've seen the movies. This just leads to problems with cocaine.\",\n",
       " \" I hate racism Comment on BlameOneNotAll: Do men who don't hurt women actually need to be congratulated? \",\n",
       " 'A new low for extremist Qatari  . Iran is behind terror attack on Shia Arab mosque in Qatif ',\n",
       " 'bagheera Maine coon black cat gatto gato chat ',\n",
       " \"  I feel a certain kinship with her, an understanding though my mother was a big bawdy 'feminazi'.\",\n",
       " 'NYS ht had died down a lot. Flurry of tweets after LawAndOrderSVU tonight. QUICKLY, MINORITIES. POINT OUT THAT ALL THESE WOMEN ARE LYING.',\n",
       " 'Get on my level, son! funrun2 Pepcman coon YOMAMA ',\n",
       " ' yeah can they be anymore racist painting black males with criminal colors is just disgustingly racist BlameOneNotAll',\n",
       " '  i see a lot. it happens a lot in chan culture, more so lately in sjw.',\n",
       " \" i took a bunch of screencaps of the harassment the conf i was speaking at received from them. that's going to be fun.\",\n",
       " \" I'm from the south. Sweetie is another way to talk down and tell someone to go fuck themselves.\",\n",
       " 'They warned me Australians were racist. Who knew they were this bad!! wtf coles coon… ',\n",
       " ' Can we re-retire the word Coon',\n",
       " '  sigh. he accused me of racism... for what, i have no idea.',\n",
       " '   I can just imagine a lobby full of dogs like this now. ',\n",
       " ' cant wait to wash my food coon',\n",
       " 'This person thinks that ~6 people tweeting at them for being a sealioning ass is the worst thing in the world.',\n",
       " ' GermanProfessor gives meaning to term FemiNazi.Doesn\\'t hire \"Indian Men\" bcz of \"Indias\\'s Rape Problem\"',\n",
       " 'The number of emails attributing my RTs of WoC/racial issues to \"spoiled white girl guilt\" is now greater than 0.',\n",
       " 'Israel’s Avigdor Lieberman calls for beheading of Arab Israelis  ISIS Qaeda Nusra Takfiri Terror',\n",
       " '  and sadly, i am not the person to tell them. :) high follower account + white cis == public enemy 1 to many.',\n",
       " ' Notorious 8chan “subboard” has history wiped after federal judge’s doxing ',\n",
       " 'isis isil terror terrorism terrorist terrorists israel islam islamic zion zionist arab ',\n",
       " 'Coon ass 👎 ',\n",
       " ' a figurative storm of shit - a shitstorm, if you will - that is now causing people to get harassed.',\n",
       " ' MKR  this shit show has more comebacks than Johnny Farnham, ok back to the TheVoiceAu',\n",
       " \" You retiring not at a sneaker show SMH No need to stunt with kicks you probably ain't pay for RT  coon htt…\",\n",
       " ' You are one of my early frontrunners for Coon of the Year... but look out... Ben Carson is looking strong as well.',\n",
       " 'totally forgot how that jerk invited me up to his office, too. lol no. my time is worth too much. stopwadhwa2015',\n",
       " ' the thing i fight with is when i see minorities mob signing off on the exact behavior they know is terrible.',\n",
       " '  Booooooooo Coon',\n",
       " \" it looks like it's white with shitty color balance.\",\n",
       " 'Mom: \"Feminazi???? Who uses that term??\"Me: \"Straight white boys who don\\'t know what feminism is\"I almost said fuckboys',\n",
       " 'Another Arab car terror attack in Jerusalem Israel. Will Obama call it random traffic infringement? ',\n",
       " ' ---&gt; PERFECT EXAMPLE OF A COON. STILL can\\'t get over the \"white nubian goddess\" comment.... FOH!!!! COON Let\\'s talk about that!',\n",
       " \" States should not let unvaccinated crumb-snatchers into schools. And the best part? It's legal if they don't. \",\n",
       " '❤️❤️ Oakland ❤️❤️blacklivesmatter ',\n",
       " ' Another Arab car ramming terror attack in Jerusalem Israel. Will Obama Adm call this random traffic infringement? ',\n",
       " \"  lol, as they should. GG is a hate group. Ghazi isn't for them.\",\n",
       " ' TROLLING YOUcuz YOU USED MORE THAN 4 WORDS!SENTENCEDto incessant needlepoint in a neo-communist FemiNazi Gulag!^_-',\n",
       " ' dude yours was the worst coon',\n",
       " 'I made the mistake of searching for pocky on Amazon. Now looking at wasabi and apple flavored Kit Kats. What. Time to move to Japan.',\n",
       " 'I order Asian food about as well as the guy taking my order can drive. notverygood',\n",
       " \"I'm not really concerned about them being here, but I'll probably crash at a friends for a few days for safety reasons.\",\n",
       " 'coon alert! morningjoe',\n",
       " ' you coon ass niggaFuckBoyCoonStraightPussyScaredOfTheMedia',\n",
       " \" GermanProfessor gives meaning to term FemiNazi.Doesn't hire Indian Men bcz of Indias's Rape Problem.\",\n",
       " ' perhaps you should hang yourself to showoff to your buddies sellout coon',\n",
       " \"sellout coon pawn this is why I don't fuck with this punk nigga. He protect the beast. He ain't a… \",\n",
       " 'STAY OFF MY PAGE COON ',\n",
       " 'DIAMOND IS DEFINITELY MONA TOP COON EXPLOITEE THIS SEASON.  MIMI IS PRAISING GOD THIS IS AIRING BEFORE LHHATL SHE NEEDED THIS LHHNY',\n",
       " \" it's pretty rad having a non-standard name. although there's getting to be more randi harpers in the world. poor things.\",\n",
       " \"Um hey truth as a black man in a company that has had past incident with racism, don't say ur going to pick anything coon\",\n",
       " 'Gris sur Gris Coon and Weather LaReunion ',\n",
       " 'Wadhwa had other women write a book about being a woman in tech, then he published it with his own name on the title. stopwadhwa2015',\n",
       " '   Then turned  tw handle (her last name) into a racial slur.',\n",
       " 'Why do Blacks Coon on television or the movies? ',\n",
       " 'That Moment When A Female Call You A Coon .. With A Head Full Of Fμ©k¡N Weave \\U000fe32d\\U000fe32d\\U000fe32d',\n",
       " 'Company profile NKC COON HUNTING, INCORPORATED - ',\n",
       " 'the enemy is grouping. it is time for death turkey. ',\n",
       " 'Hashtag killerblondes is the dickiest hashtag in all  MKR history... Seriously... Why not butcherthemodels',\n",
       " 'STUPID IS WHAT STUPID DOES... ALL ABOARD THE COON TRAIN... ',\n",
       " \"KayneWest is a Straight Coon! 30 showers bcuz of Muva? Gtfoh w/that BS! So after Kim you'll take 3000, rt?\",\n",
       " \"Sickened but not surprised by what happened at PAX earlier today. PAX has a history of making poor decisions at the cost of women's safety.\",\n",
       " 'ISRAEL FOREVER BLOG/ Terror attack in Jerusalem injures seven, terrorist shot - ',\n",
       " ' Another Arab car terror attack in Jerusalem Israel. Will Obama call it random traffic infringement? ',\n",
       " 'Possible kickstarter reward: I will personally dye your hair your bright color of choice',\n",
       " \"  I was *shocked* they didn't try to darken skin colors.\",\n",
       " 'She also claimed that women being angry with Wadhwa was worse than the death threats we were getting because we\\'re \"used to it\".',\n",
       " ' I am begging them to never give him a mic again. Coon',\n",
       " '&lt;tsui-ji&gt; gyl: go into asian and tell em you are white, have muscles and drive a nice car and mad chicks will msg you',\n",
       " \"I'm not worried about a bitch that live with her mother you can't even get a place in your name you got rules stay in a child's place COON\",\n",
       " \" call out culture goes both ways, and it's responsible for driving people off of twitter. Today, JW. Tomorrow, who knows?\",\n",
       " \"ethics in journalism. ETHICS. IN. JOURRRRRRRNALISM. No wonder he's friends with that walking burrito fart, milo.\",\n",
       " \" as a white woman, it's none of my business to comment on if i like that term or not.\",\n",
       " \"    why are these people such idiots, i mean, seriously. it's not difficult code to read.\",\n",
       " \" as a concept, it's fantastic. as a community? way too toxic, way too enabling of harassment as long as it's for a cause.\",\n",
       " ' coon',\n",
       " 'My newest love babyraccoon coon ',\n",
       " 'Headed out coon hunting with some friends on the back of the farm. This is his first time. Kinda… ',\n",
       " ' Your picture creeps me the fuck out. Coon xD',\n",
       " 'BRRRR 80 degrees yesterday 40 today and windy.  Coon ass on ice.',\n",
       " \"jumping in the  BlameOneNotAll tag.I expect to find all kinds of bigoted fucktards telling me how I'm the problem \",\n",
       " 'Arab Man Arrested Trying To Enter Same Nuclear Facility Warned: ',\n",
       " '  look dude, i want to be nice to you, but FUCK OFF. you got harassed by a spam bot. leave me alone.',\n",
       " 'Coon style supercoon he said I work with some funny folks coonstyle  ',\n",
       " 'Ole Annie on that tree!! She was fired up!! barnsidekennelsjk ready to go again. coon hunting… ',\n",
       " '“ someone said he hit The Whip mid fight. I need confirmation lol.” I dont even need confirmation I know he did it lol coon',\n",
       " \"This was in 2013 I didn't know bout it..Russell Simmons put out this garbage..fuck that coon knew he… \",\n",
       " 'Egyptian president wants joint Arab force to fight Islamist terror: ',\n",
       " \"Y'all make sure y'all following a nigga coon⛽🅰🆖💯lilbitch 😹😹👌 joeworld\",\n",
       " ' great job cOOning tonight donlemon coon',\n",
       " ' WHADDUP EVERYBODY!! New Crispy Show episodes coming soon! puppet jokes coon ',\n",
       " ' ... i hate shadowrun. :P',\n",
       " ' You can just see her credentials.  Black FemiNazi.',\n",
       " 'Libya Accuses US of Trying to Put Muslim brotherhood in Power ',\n",
       " '   and why was the statement \"white women only\"',\n",
       " '\"ally in social media is a slang word. my slang is not good.\" oh, here come allegations of racism. countdown.',\n",
       " ' nothing will ever be perfect, but this is a good start towards fixing a HUGE percentage of harassment.',\n",
       " \"omfg blackmilk you're killing me \",\n",
       " ' i think every white person has some level of bias and has to keep that in mind.',\n",
       " \"color me surprised when i look up dude defending piracy on linkedin and he's some young white dude claiming to be a CTO.\",\n",
       " \"  Would you prefer I say Massa. Oh I don't wana speak ill of my masse da white man. housenigga coon\",\n",
       " \" in their defense, some incarnations of jubilee weren't portrayed as asian.\",\n",
       " \" Wadhwa is an unapologetic furtherer of Shanley's abusive Neo Nazi ex, Weev. stopwadhwa2015\",\n",
       " '  dude we were the best team ever. We made shit happen! aggies Coon',\n",
       " ' i believe in call-out culture against people that are known to be *deliberate* in their harm.',\n",
       " 'Another Arab car ramming terror attack in Jerusalem Israel. Will Obama Adm call this random traffic infringement? ',\n",
       " 'I see mein public shaming vorked. Zee vile CarolCorps vill now have black members in zee comics. Strucker: I put zee Nazi in FemiNazi',\n",
       " \" KayneWest is a Straight Coon! 30 showers bcuz of Muva? Gtfoh w/that BS! So after Kim you'll take 3000, rt?\",\n",
       " 'Fresh off the plantation front row at the nigger Olympics smh Coon ',\n",
       " \"An old dude today told me that when he lived in Paris, he saw many people with colorful hair. TIL Paris's primary export is SJWs.\",\n",
       " 'Thank u God for blessing real hustlers &amp; for real niggas MEEKMILLSEASON s/o Coon ... (Vine by TheTheoryis) ',\n",
       " ' It’s men’s job to fix sexism. White ppl -&gt; racism Straight ppl -&gt; homophobia. Cis ppl -&gt; transphobia.NOT the oppressed’…',\n",
       " \"But I'll be real with you. Anytime a white guy talks about safe spaces and his personal opinion on them, I kinda roll my eyes.\",\n",
       " \"   man fuck these feminazi s Kube. We don't need a black history month. Blacks don't care why solo them out\",\n",
       " ' i know it\\'s really just a small number of people being vocally \"randi is a racist/terf,\" and they are suffering from abuse, but']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "exclusive-aruba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are '2111' items in our data frame.\n",
      "Data frame contents: \n",
      "              words\n",
      "these         these\n",
      "girl          girls\n",
      "are             are\n",
      "the             the\n",
      "equival  equivalent\n",
      "of               of\n",
      "the             the\n",
      "irrit    irritating\n",
      "asian         asian\n",
      "girl          girls\n"
     ]
    }
   ],
   "source": [
    "totalvocab_stemmed = []\n",
    "totalvocab_tokenized = []\n",
    "for i in texts:\n",
    "    allwords_stemmed = tokenize_and_stem(i)\n",
    "    totalvocab_stemmed.extend(allwords_stemmed)\n",
    "    \n",
    "    allwords_tokenized = tokenize_only(i)\n",
    "    totalvocab_tokenized.extend(allwords_tokenized)\n",
    "\n",
    "# Create a pandas DataFrame\n",
    "vocab_frame = pd.DataFrame({'words': totalvocab_tokenized}, index = totalvocab_stemmed)\n",
    "\n",
    "print(\"There are '{}' items in our data frame.\".format(str(vocab_frame.shape[0])))\n",
    "print(\"Data frame contents: \\n{}\".format(vocab_frame.head(10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caring-andrew",
   "metadata": {},
   "source": [
    "#### TF-IDF\n",
    "\n",
    "Add stopwords that often occur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "northern-church",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\", 'u', \"i'v\", \"you'v\", \"you'r\", \"i'm\", 'mkr', 'whi']\n"
     ]
    }
   ],
   "source": [
    "stopword_list = stopwords.words(\"english\")\n",
    "stopword_list.extend([\"u\"])\n",
    "stopword_list.extend([\"i'v\"])\n",
    "stopword_list.extend([\"you'v\"])\n",
    "stopword_list.extend([\"you'r\"])\n",
    "stopword_list.extend([\"i'm\"])\n",
    "stopword_list.extend([\"mkr\", \"whi\"])\n",
    "\n",
    "\n",
    "print(stopword_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fewer-telephone",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 49.9 ms\n",
      "TF-IDF matrix shape: (140, 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matij\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:391: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'becaus', 'befor', 'doe', 'dure', 'onc', 'onli', 'ourselv', \"should'v\", 'themselv', 'veri', 'yourselv'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "# Define vectorizer parameters\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "                        max_df=0.60, \n",
    "                        max_features=None,\n",
    "                        min_df=0.05,  \n",
    "                        use_idf=True, \n",
    "                        stop_words= stopword_list,\n",
    "                        tokenizer=tokenize_and_stem, \n",
    "                        ngram_range=(1,1))\n",
    "\n",
    "#tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit the vectorizer to synopses texts\n",
    "%time tfidf_matrix = tfidf_vectorizer.fit_transform(texts) \n",
    "\n",
    "\n",
    "print(\"TF-IDF matrix shape: {}\".format(tfidf_matrix.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea94a04a",
   "metadata": {},
   "source": [
    "### Extracted keywords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "inclusive-better",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['peopl' 'white' 'terror' 'man' 'look']\n"
     ]
    }
   ],
   "source": [
    "feature_array = np.array(tfidf_vectorizer.get_feature_names())\n",
    "tfidf_sorting = np.argsort(tfidf_matrix.toarray()).flatten()[::-1]\n",
    "\n",
    "n = 5\n",
    "top_n = feature_array[tfidf_sorting][:n]\n",
    "print(top_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188bce2d",
   "metadata": {},
   "source": [
    "# Following part is commented out - not used and tested\n",
    "\n",
    "This were some initial experiments that are not included anywhere in the report."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seeing-zoning",
   "metadata": {},
   "source": [
    "#### Use cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "touched-young",
   "metadata": {},
   "outputs": [],
   "source": [
    "#terms = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "#dist = 1 - cosine_similarity(tfidf_matrix)\n",
    "#print(dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bored-graphic",
   "metadata": {},
   "source": [
    "#### Use k-means clustering\n",
    "##### First choose optimal number of clusters using the silhouette score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nasty-double",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "range_clusters = list(range(2,10))\n",
    "for num_clusters in range_clusters:\n",
    "    km = KMeans(n_clusters=num_clusters)\n",
    "    km.fit(tfidf_matrix)\n",
    "    clusters = km.labels_.tolist()\n",
    "    silhouette_avg = silhouette_score(tfidf_matrix, clusters)\n",
    "    print(f\"{num_clusters} clusters - silhouette: {silhouette_avg}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excellent-bhutan",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "num_clusters = 3\n",
    "km = KMeans(n_clusters=num_clusters)\n",
    "\n",
    "# Perform clustering\n",
    "%time km.fit(tfidf_matrix)\n",
    "\n",
    "clusters = km.labels_.tolist()\n",
    "print(\"Clusters: {}\".format(clusters))\n",
    "\n",
    "print(len(clusters))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "great-mobility",
   "metadata": {},
   "source": [
    "#### Get number of tweets per cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standard-filename",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "tweets = {\"label\": labels, \"text\": texts, \"cluster\": clusters}\n",
    "frame = pd.DataFrame(tweets, index = [clusters] , columns = [\"label\", \"text\", \"cluster\"])\n",
    "\n",
    "print(\"Number of tweets per cluster: \\n{}\".format(frame[\"cluster\"].value_counts()))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liable-registration",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "print(\"Top terms per cluster:\\n\")\n",
    "\n",
    "# Sort cluster centers by proximity to centroid.\n",
    "order_centroids = km.cluster_centers_.argsort()[:, ::-1] \n",
    "print(order_centroids)\n",
    "\n",
    "# Helper function\n",
    "def getClusterWords(cluster, n=10):\n",
    "    words = []\n",
    "    for ind in order_centroids[cluster, :n]: # Print 6 words per cluster\n",
    "        words.append(vocab_frame.loc[terms[ind].split(' '),].values.tolist()[0][0])\n",
    "    return \", \".join(words)\n",
    "\n",
    "for i in range(num_clusters):\n",
    "    print(\"Cluster {} words: {}\".format(i, getClusterWords(i)))\n",
    "    \n",
    "    print(\"Cluster {} labels:\".format(i), end='')\n",
    "    \n",
    "    for label in frame[frame[\"cluster\"]==i][\"label\"].values.tolist():\n",
    "        print(\" {},\".format(label), end='')\n",
    "    print(\"\\n\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranging-stamp",
   "metadata": {},
   "source": [
    "#### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documentary-helena",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from sklearn.manifold import MDS\n",
    "\n",
    "# Parameter \"precomputed\" because we provide a distance matrix.\n",
    "# Parameter \"random_state\" so the plot is reproducible.\n",
    "mds = MDS(n_components=2, dissimilarity=\"precomputed\", random_state=1)\n",
    "\n",
    "# Shape of the result will be (n_components, n_samples).\n",
    "pos = mds.fit_transform(dist)  \n",
    "\n",
    "xs, ys = pos[:, 0], pos[:, 1]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "correct-russian",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Define colors for clusters.\n",
    "cluster_colors = {0: '#1b9e77', 1: '#d95f02', 2: '#7570b3', 3: '#e7298a', 4: '#66a61e'}\n",
    "\n",
    "# Define cluster names\n",
    "cluster_names = dict([(i, getClusterWords(i, 3)) for i in range(5)])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powered-knife",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "# Enable to draw plot inline.\n",
    "%matplotlib inline\n",
    "\n",
    "# Create a data frame that has the result of the MDS plus the cluster numbers and titles.\n",
    "df = pd.DataFrame(dict(x=xs, y=ys, label=clusters)) \n",
    "\n",
    "# Group by cluster.\n",
    "groups = df.groupby('label')\n",
    "\n",
    "\n",
    "# Set up plot.\n",
    "fig, ax = plt.subplots(figsize=(17, 9)) # set size\n",
    "ax.margins(0.05) # Optional, just adds 5% padding to the autoscaling\n",
    "\n",
    "# Iterate through groups to layer the plot.\n",
    "# Note that we use the cluster_name and cluster_color dicts with the 'name' \n",
    "# lookup to return the appropriate color/label.\n",
    "for name, group in groups:\n",
    "    ax.plot(group.x, group.y, marker='o', linestyle='', ms=12, \n",
    "            label=cluster_names[name], color=cluster_colors[name], \n",
    "            mec='none')\n",
    "    ax.set_aspect('auto')\n",
    "    ax.tick_params(\\\n",
    "        axis= 'x',         # changes apply to the x-axis\n",
    "        which='both',      # both major and minor ticks are affected\n",
    "        bottom='off',      # ticks along the bottom edge are off\n",
    "        top='off',         # ticks along the top edge are off\n",
    "        labelbottom='off')\n",
    "    ax.tick_params(\\\n",
    "        axis= 'y',         # changes apply to the y-axis\n",
    "        which='both',      # both major and minor ticks are affected\n",
    "        left='off',        # ticks along the bottom edge are off\n",
    "        top='off',         # ticks along the top edge are off\n",
    "        labelleft='off')\n",
    "    \n",
    "ax.legend(numpoints=1)  #show legend with only 1 point\n",
    "\n",
    "# Add label in x,y position with the label as the film title.\n",
    "for i in range(len(df)):\n",
    "    # old pandas:\n",
    "    #ax.text(df.ix[i]['x'], df.ix[i]['y'], df.ix[i]['title'], size=8) \n",
    "    ax.text(df.loc[df.index[i], 'x'], df.loc[df.index[i], 'y'], df.loc[df.index[i], 'title'], size=8)  \n",
    "\n",
    "# Uncomment the below to show or save the plot.\n",
    "plt.show()                                       #show the plot\n",
    "#plt.savefig('clusters_small_noaxes.png', dpi=200) # save the plot as an image \n",
    "\n",
    "plt.close()\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlp] *",
   "language": "python",
   "name": "conda-env-nlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
