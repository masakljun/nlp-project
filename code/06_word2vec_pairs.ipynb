{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "controlled-stick",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import gensim.downloader\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.manifold import MDS\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import tempfile\n",
    "import imageio\n",
    "import shutil\n",
    "import os\n",
    "from statistics import mean\n",
    "import pandas as pd \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.stem import PorterStemmer \n",
    "from gensim.test.utils import datapath\n",
    "from gensim.models.fasttext import load_facebook_vectors\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.display import display\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "import matplotlib.patheffects as PathEffects\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "%matplotlib inline\n",
    "\n",
    "from matplotlib.axes._axes import _log as matplotlib_axes_logger\n",
    "matplotlib_axes_logger.setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "occasional-entertainment",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wv = gensim.downloader.load('word2vec-google-news-300')\n",
    "#model_g = gensim.downloader.load('glove-wiki-gigaword-300')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appropriate-province",
   "metadata": {},
   "source": [
    "#### Find pairs\n",
    "Paris is to France as Berlin is to ?\n",
    "\n",
    "Paris : France :: Berin : ?\n",
    "\n",
    "France - Paris + Berlin = ?\n",
    "\n",
    "? = Germany"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clean-damages",
   "metadata": {},
   "source": [
    "sims = model_wv.most_similar(positive=['France', 'Berlin'], negative=['Paris'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raising-lawsuit",
   "metadata": {},
   "source": [
    "### Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "interested-influence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('institutionalized_racism', 0.7096136808395386),\n",
       " ('homophobia', 0.7021567821502686),\n",
       " ('Racism', 0.6871979832649231),\n",
       " ('racial_discrimination', 0.6775422692298889),\n",
       " ('bigotry', 0.6737836599349976),\n",
       " ('racial_prejudice', 0.6732275485992432),\n",
       " ('racial_intolerance', 0.6541361808776855),\n",
       " ('racist', 0.6478179693222046),\n",
       " ('racial_bigotry', 0.6457424163818359),\n",
       " ('blatant_racism', 0.6429591178894043)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims1 = model_wv.most_similar(positive=['father', 'racism'], negative=['son'])\n",
    "#sims2 = model_g.most_similar(positive=['father', 'racism'], negative=['son'])\n",
    "sims1\n",
    "#print(sims2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "valuable-repair",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('racism', 0.7008050680160522),\n",
       " ('homophobic', 0.6619293689727783),\n",
       " ('bigotry', 0.6219342350959778),\n",
       " ('homophobic_attitudes', 0.6141318082809448),\n",
       " ('Homophobia', 0.6102346777915955),\n",
       " ('homosexuality', 0.6007557511329651),\n",
       " ('gay_bashing', 0.5969532132148743),\n",
       " ('gay', 0.588276743888855),\n",
       " ('racial_intolerance', 0.5835667252540588),\n",
       " ('sexism', 0.5829565525054932)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims1 = model_wv.most_similar(positive=['father', 'homophobia'], negative=['son'])\n",
    "#sims2 = model_g.most_similar(positive=['father', 'racism'], negative=['son'])\n",
    "print(sims1)\n",
    "#print(sims2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "above-reading",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('defensive', 0.5628560781478882),\n",
       " ('Offensive', 0.5497417449951172),\n",
       " ('offense', 0.5321450233459473),\n",
       " ('Dave_Borbely', 0.4998655915260315),\n",
       " ('guard_RJ_Mattes', 0.4856271743774414),\n",
       " ('coach_Bob_Palcic', 0.48259398341178894),\n",
       " ('coach_Jimmy_Heggins', 0.47518685460090637),\n",
       " ('offensively', 0.47009724378585815),\n",
       " ('coach_Dan_Cozzetto', 0.4652729332447052),\n",
       " ('coach_Dave_Magazu', 0.46430879831314087)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims = model_wv.most_similar(positive=['brother', 'offensive'], negative=['sister'])\n",
    "sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "resistant-mobility",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('defensive', 0.6267510652542114),\n",
       " ('Offensive', 0.6130504012107849),\n",
       " ('coach_Bob_Palcic', 0.5567697286605835),\n",
       " ('offensively', 0.5524480938911438),\n",
       " ('offense', 0.5397347807884216),\n",
       " ('Dave_Borbely', 0.5268849730491638),\n",
       " ('guard_RJ_Mattes', 0.525318443775177),\n",
       " ('promoted_Pete_Metzelaars', 0.5250057578086853),\n",
       " ('coach_Jimmy_Heggins', 0.523449182510376),\n",
       " ('coach_George_Yarno', 0.5208775997161865)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims = model_wv.most_similar(positive=['father', 'offensive'], negative=['son'])\n",
    "sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "junior-detection",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Offensive', 0.6361226439476013),\n",
       " ('defensive', 0.6109646558761597),\n",
       " ('offense', 0.5482767820358276),\n",
       " ('offensively', 0.5432956218719482),\n",
       " ('guard_RJ_Mattes', 0.5229091644287109),\n",
       " ('Offensively', 0.5038000345230103),\n",
       " ('coach_Bob_Palcic', 0.5025234222412109),\n",
       " ('Pashtun_Zarghun_district', 0.5010451078414917),\n",
       " ('coach_Jimmy_Heggins', 0.49560749530792236),\n",
       " ('playmakers', 0.4946232736110687)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims = model_wv.most_similar(positive=['son', 'offensive'], negative=['father'])\n",
    "sims"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expensive-order",
   "metadata": {},
   "source": [
    "### Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "wanted-richardson",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_g = gensim.downloader.load('glove-wiki-gigaword-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ruled-official",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('slurs', 0.5391111969947815),\n",
       " ('homophobic', 0.44801968336105347),\n",
       " ('derogatory', 0.4413053095340729),\n",
       " ('disparaging', 0.41294431686401367),\n",
       " ('epithets', 0.40569791197776794),\n",
       " ('uttered', 0.4046255946159363),\n",
       " ('racist', 0.4021945297718048),\n",
       " ('nigger', 0.39872631430625916),\n",
       " ('remark', 0.3884381055831909),\n",
       " ('insult', 0.37972599267959595)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims2 = model_g.most_similar(positive=['brother', 'slur'], negative=['sister'])\n",
    "sims2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "controlled-sodium",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('slurs', 0.6233149170875549),\n",
       " ('derogatory', 0.5212036371231079),\n",
       " ('homophobic', 0.5057779550552368),\n",
       " ('epithets', 0.5045928955078125),\n",
       " ('uttered', 0.4736688435077667),\n",
       " ('disparaging', 0.4691711962223053),\n",
       " ('profanities', 0.46358582377433777),\n",
       " ('obscenities', 0.44784194231033325),\n",
       " ('nigger', 0.4412068724632263),\n",
       " ('remark', 0.4186044931411743)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims2 = model_g.most_similar(positive=['son', 'slur'], negative=['father'])\n",
    "sims2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "advisory-certificate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('slurs', 0.6650111079216003),\n",
       " ('derogatory', 0.5520739555358887),\n",
       " ('disparaging', 0.5134429931640625),\n",
       " ('homophobic', 0.5107932686805725),\n",
       " ('racist', 0.5039888620376587),\n",
       " ('epithets', 0.494453489780426),\n",
       " ('racial', 0.48461052775382996),\n",
       " ('stereotyping', 0.48268580436706543),\n",
       " ('sexist', 0.46767958998680115),\n",
       " ('semitic', 0.46574753522872925)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims2 = model_g.most_similar(positive=['father', 'slur'], negative=['son'])\n",
    "sims2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "french-albert",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlp] *",
   "language": "python",
   "name": "conda-env-nlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
